{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN for Cancer Signaling: Full-Range Training Demo\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Train a PINN on the full time range [0,1,4,8,24,48]hrs\n",
    "2. Visualize training fit across the full timeline\n",
    "3. Use the trained model for downstream inference\n",
    "\n",
    "**Drug Combination**: Vemurafenib (0.5) + Trametinib (0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from train_pinn import train_pinn\n",
    "from visualize_extrapolation import (\n",
    "    plot_extrapolation_results, \n",
    "    plot_training_history, \n",
    "    generate_prediction_table,\n",
    "    load_pinn_with_data\n",
    ")\n",
    "from data_utils import TRAINING_DATA_RAW, SPECIES_ORDER\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Configure Training Parameters\n",
    "\n",
    "The model will train on all available time points (0\u201348h).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'train_until_hour': 48,\n",
    "    'num_epochs': 10000,\n",
    "    'learning_rate': 0.001,\n",
    "    'lr_decay': 0.95,\n",
    "    'batch_size': 6,  # 6 training time points\n",
    "    'hidden_size': 100,\n",
    "    'num_physics_points': 100,\n",
    "    'weight_decay': 1e-5,\n",
    "    'weights': {\n",
    "        'data': 1.0,\n",
    "        'physics': 0.5,\n",
    "        'boundary': 0.3,\n",
    "        'conservation': 0.2\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(\"  Training on: [0, 1, 4, 8, 24, 48] hours\")\n",
    "print(\"  Testing on: None (full-range training)\")\n",
    "print(f\"  Epochs: {config['num_epochs']}\")\n",
    "print(f\"  Physics weight: {config['weights']['physics']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train the Model\n",
    "\n",
    "This will take several minutes. The progress bar shows train loss (test loss is N/A for full-range training).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run if you want to train from scratch\n",
    "# Otherwise, skip to the next cell to load a pre-trained model\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING: Vem+Tram at [0,1,4,8,24,48]hrs\")\n",
    "print(\"TESTING: No held-out time points (full data training)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model, k_params, history, scalers, train_data, test_data = train_pinn(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Trained Model\n",
    "\n",
    "Load the best checkpoint (either from training above or a pre-trained model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('pinn_model_best.pth'):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model, scalers, train_data, test_data = load_pinn_with_data('pinn_model_best.pth', device)\n",
    "    print(\"\u2713 Model loaded successfully!\")\n",
    "    print(f\"  Device: {device}\")\n",
    "    print(f\"  Training points: {train_data['t']}\")\n",
    "    if test_data is not None and len(test_data['t']) > 0:\n",
    "        print(f\"  Test points: {test_data['t']}\")\n",
    "    else:\n",
    "        print(\"  Test points: None (full-range training)\")\n",
    "else:\n",
    "    print(\"\u26a0 No trained model found. Run the training cell above first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Visualize Training Fit\n",
    "\n",
    "This creates a comprehensive plot showing model predictions and training data across the full 0\u201348h range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_extrapolation_results()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Training History Analysis\n",
    "\n",
    "Track how loss evolved over epochs. Test loss will be NaN for full-range training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history()\n",
    "plt.show()\n",
    "\n",
    "# Show final losses\n",
    "history_df = pd.read_csv('training_history.csv')\n",
    "final_epoch = history_df.iloc[-1]\n",
    "print(\"\\nFinal Performance:\")\n",
    "print(f\"  Train Loss: {final_epoch['l_data']:.6f}\")\n",
    "if pd.notna(final_epoch['l_test']):\n",
    "    print(f\"  Test Loss: {final_epoch['l_test']:.6f}\")\n",
    "    print(f\"  Test/Train Ratio: {final_epoch['l_test']/final_epoch['l_data']:.2f}\")\n",
    "else:\n",
    "    print(\"  Test Loss: N/A (full-range training)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Detailed Predictions Table\n",
    "\n",
    "Generate a table with predicted vs. true values for all time points and species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = generate_prediction_table()\n",
    "\n",
    "# Show predictions at test time points only if they exist\n",
    "test_predictions = predictions_df[predictions_df['Dataset'] == 'Test']\n",
    "if not test_predictions.empty:\n",
    "    print(\"\\nTest Set Predictions (24 and 48 hours):\")\n",
    "    print(test_predictions[['Time (hrs)', 'Species', 'True Value', 'Predicted Value', 'Percent Error']].to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo held-out test points (full-range training).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Species-Specific Analysis\n",
    "\n",
    "Inspect per-species fit across the timeline (test points are optional).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute R\u00b2 for each species on test set if available\n",
    "test_r2 = {}\n",
    "\n",
    "if not test_predictions.empty:\n",
    "    for species in SPECIES_ORDER:\n",
    "        species_data = test_predictions[test_predictions['Species'] == species]\n",
    "        y_true = species_data['True Value'].values\n",
    "        y_pred = species_data['Predicted Value'].values\n",
    "        \n",
    "        ss_res = np.sum((y_true - y_pred)**2)\n",
    "        ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
    "        r2 = 1 - (ss_res / (ss_tot + 1e-8))\n",
    "        test_r2[species] = r2\n",
    "\n",
    "    # Sort by extrapolation quality\n",
    "    r2_df = pd.DataFrame(list(test_r2.items()), columns=['Species', 'Test R\u00b2'])\n",
    "    r2_df = r2_df.sort_values('Test R\u00b2', ascending=False)\n",
    "\n",
    "    print(\"\\nExtrapolation Quality by Species:\")\n",
    "    print(r2_df.to_string(index=False))\n",
    "\n",
    "    # Bar plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = ['green' if r2 > 0.8 else 'orange' if r2 > 0.6 else 'red' for r2 in r2_df['Test R\u00b2']]\n",
    "    plt.bar(r2_df['Species'], r2_df['Test R\u00b2'], color=colors)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Test R\u00b2')\n",
    "    plt.title('Extrapolation Quality by Species')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nNo held-out test points (full-range training).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Biological Interpretation\n",
    "\n",
    "Check if the model learned expected dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint to inspect learned rate constants\n",
    "checkpoint = torch.load('pinn_model_best.pth', map_location='cpu')\n",
    "k_params = checkpoint['k_params_state_dict']\n",
    "\n",
    "print(\"Learned Kinetic Parameters:\")\n",
    "for name, value in k_params.items():\n",
    "    print(f\"  {name}: {value.item():.4f}\")\n",
    "\n",
    "# Expected dynamics from biology\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Expected Biological Behavior (Vem+Tram):\")\n",
    "print(\"=\"*60)\n",
    "print(\"\u2713 pMEK: Should be LOW (Trametinib inhibits MEK)\")\n",
    "print(\"\u2713 pERK: Should be LOW (blocked MEK \u2192 blocked ERK)\")\n",
    "print(\"\u2713 DUSP6: Should DECREASE over time (less ERK activation)\")\n",
    "print(\"\u2713 pAKT: Should INCREASE (compensatory PI3K activation)\")\n",
    "print(\"\u2713 HER3: May INCREASE (feedback receptor upregulation)\")\n",
    "\n",
    "# Check if predictions match\n",
    "pMEK_48 = predictions_df[(predictions_df['Time (hrs)'] == 48) & (predictions_df['Species'] == 'pMEK')]['Predicted Value'].values[0]\n",
    "pERK_48 = predictions_df[(predictions_df['Time (hrs)'] == 48) & (predictions_df['Species'] == 'pERK')]['Predicted Value'].values[0]\n",
    "pAKT_48 = predictions_df[(predictions_df['Time (hrs)'] == 48) & (predictions_df['Species'] == 'pAKT')]['Predicted Value'].values[0]\n",
    "\n",
    "print(\"\\nModel Predictions at 48hrs:\")\n",
    "print(f\"  pMEK: {pMEK_48:.3f} (expect LOW)\")\n",
    "print(f\"  pERK: {pERK_48:.3f} (expect LOW)\")\n",
    "print(f\"  pAKT: {pAKT_48:.3f} (expect ELEVATED)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load data from the model checkpoint\n",
    "from visualize_extrapolation import load_pinn_with_data, SPECIES_ORDER, TRAINING_DATA_RAW\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model, scalers, train_data, test_data = load_pinn_with_data('pinn_model_best.pth', device)\n",
    "has_test_data = test_data is not None and len(test_data['t']) > 0\n",
    "\n",
    "# 2. Generate smooth predictions across 0-48h\n",
    "t_smooth = np.linspace(0, 48, 500)\n",
    "drugs_raw = TRAINING_DATA_RAW['drugs']\n",
    "y_smooth = model.predict(t_smooth, drugs_raw, scalers, device)\n",
    "\n",
    "# 3. Plotting grid\n",
    "fig, axes = plt.subplots(4, 3, figsize=(18, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, species in enumerate(SPECIES_ORDER):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot smooth PINN curve\n",
    "    ax.plot(t_smooth, y_smooth[:, i], label='PINN Prediction', color='blue', linewidth=2)\n",
    "    \n",
    "    # Plot Training points\n",
    "    ax.scatter(train_data['t'], train_data['y'][:, i],\n",
    "               color='green', marker='o', s=80, label='Train Data (Input)', zorder=5)\n",
    "    \n",
    "    # Plot Test points if present\n",
    "    if has_test_data:\n",
    "        ax.scatter(test_data['t'], test_data['y'][:, i],\n",
    "                   color='red', marker='s', s=80, label='Test Data (Hidden)', zorder=5)\n",
    "        ax.axvline(x=8, color='black', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    ax.set_title(f\"Dynamic Fit: {species}\", fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel(\"Time (hours)\")\n",
    "    ax.set_ylabel(\"Concentration (a.u.)\")\n",
    "    ax.grid(alpha=0.2)\n",
    "    if i == 0: ax.legend()\n",
    "\n",
    "# Hide unused plot\n",
    "axes[-1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What Did We Learn?\n",
    "\n",
    "1. **Full-Range Training**: The model was trained on all available time points (0\u201348h).\n",
    "2. **Physics Constraints**: ODE regularization helps the model learn biologically plausible dynamics.\n",
    "3. **Training Fit Quality**: R\u00b2 across training points indicates how well the model captures dynamics.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Adjust `config['weights']['physics']` to see how physics strength affects the fit\n",
    "- Use the trained model for new drug combinations (e.g., PI3Ki + Vemurafenib)\n",
    "- Run multiple training runs with different random seeds for uncertainty quantification\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odeNET ",
   "language": "python",
   "name": "odenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}